{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Basic usage of amica\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import amica\nimport matplotlib.pyplot as plt\nimport mne"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_path = amica.datasets.data_path()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "initial_weights, initial_scales, initial_locations = amica.utils.load_initial_weights(\n    data_path / \"eeglab_sample_data\" / \"amicaout_test\", n_components=32, n_mixtures=3\n    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "amica_outdir = data_path / \"eeglab_sample_data\" / \"amicaout_test\"\nfortran_results = amica.utils.load_fortran_results(\n    amica_outdir, n_components=32, n_mixtures=3\n    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raw = mne.io.read_raw_eeglab(\n    data_path / \"eeglab_sample_data\"/ \"eeglab_data.set\", preload=True\n    )\ndata = raw.get_data().T  # Shape (n_samples, n_channels)\ndata *= 1e6  # Convert from Volts to microVolts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "S, mean, gm, mu, rho, sbeta, W, A, c, alpha, LL = amica.fit_amica(\n        X=data,\n        max_iter=200,\n        initial_weights=initial_weights,\n        initial_scales=initial_scales,\n        initial_locations=initial_locations,\n        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "A_fortran = fortran_results['A']\ndef plot_topomaps(A, output=\"python\"):\n    fig, ax = plt.subplots(\n        nrows=8,\n        ncols=4,\n        figsize=(8, 12),\n        constrained_layout=True\n        )\n    for i, this_ax in zip(range(32), ax.flat):\n        mne.viz.plot_topomap(\n            A[:, i] if output == \"python\" else A_fortran[:, i],\n            pos=raw.info,\n            axes=this_ax,\n            show=False,\n        )\n        this_ax.set_title(f\"Component {i}\")\n    fig.suptitle(f\"AMICA Component Topomaps ({output})\", fontsize=16)\n    return fig, ax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig1, ax1 = plot_topomaps(A, output=\"python\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig2, ax2 = plot_topomaps(A_fortran, output=\"fortran\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}